{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8j3GbrVb8J9"
      },
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Cuu43wYZcXw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_sentences.txt', 'r', encoding='utf-8') as f:\n",
        "    sentences = f.read().splitlines()\n",
        "\n",
        "with open('train_nes.txt', 'r', encoding='utf-8') as f:\n",
        "    tags = f.read().splitlines()\n",
        "\n",
        "with open('train_tokens.txt', 'r', encoding='utf-8') as f:\n",
        "    tokens = f.read().splitlines()\n",
        "\n",
        "with open('train_sentences_enhanced.txt', 'r', encoding='utf-8') as f:\n",
        "    sentences_enhanced = f.read().splitlines()"
      ],
      "metadata": {
        "id": "Zuuj-zh6cCaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Load the training data\n",
        "with open('train_sentences.txt', 'r', encoding='utf-8') as f:\n",
        "    sentences = f.read().splitlines()\n",
        "\n",
        "with open('train_nes.txt', 'r', encoding='utf-8') as f:\n",
        "    tags = f.read().splitlines()\n",
        "\n",
        "with open('train_tokens.txt', 'r', encoding='utf-8') as f:\n",
        "    tokens = f.read().splitlines()\n",
        "\n",
        "with open('train_sentences_enhanced.txt', 'r', encoding='utf-8') as f:\n",
        "    sentences_enhanced = f.read().splitlines()\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
        "tag_mapping = {}\n",
        "for sentence_tags in tags:\n",
        "    tokens_tags = sentence_tags.split()\n",
        "    for token_tag in tokens_tags:\n",
        "        if '/' in token_tag:\n",
        "            token, tag = token_tag.split('/')\n",
        "            tag_mapping[token] = tag\n",
        "\n",
        "# Assign a default tag 'O' to tokens not found in tag_mapping\n",
        "default_tag = 'O'\n",
        "y = [[tag_mapping.get(token, default_tag) for token in sentence] for sentence in tokenized_sentences]\n",
        "\n",
        "# Step 3: Prepare the training data\n",
        "X = tf.ragged.constant([[tokens.index(token) if token in tokens else 0 for token in sentence] for sentence in tokenized_sentences])\n",
        "y = tf.ragged.constant([[tag_mapping.get(token, default_tag) for token in sentence] for sentence in tokenized_sentences])\n",
        "\n",
        "# Convert ragged tensors to regular Python lists\n",
        "X = X.to_list()\n",
        "y = y.to_list()\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "# Step 4: Build a sequence labeling model\n",
        "embedding_dim = 100\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokens), output_dim=embedding_dim))\n",
        "model.add(LSTM(hidden_units, return_sequences=True))\n",
        "model.add(Dense(len(tag_set), activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_SLOaYe8mP",
        "outputId": "37527c2b-f8a6-4d62-d556-d0ad867c85bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-fe7b64758470>:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_train = np.array(X_train)\n",
            "<ipython-input-17-fe7b64758470>:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X_val = np.array(X_val)\n",
            "<ipython-input-17-fe7b64758470>:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_train = np.array(y_train)\n",
            "<ipython-input-17-fe7b64758470>:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_val = np.array(y_val)\n"
          ]
        }
      ]
    }
  ]
}